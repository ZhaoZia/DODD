# DODD
Disaster Occlusion Detection Dataset (DODD)
Dataset Description

The Disaster Occlusion Detection Dataset (DODD) is a specialized dataset created to enhance the study of human detection in occlusion-heavy disaster environments. This dataset was developed by combining images from various publicly available datasets, specifically focusing on scenarios typical in disaster response, such as fires, earthquakes, and floods. DODD aims to address the critical challenges of detecting partially occluded individuals in natural disaster scenarios, providing a valuable resource for search and rescue (SAR) operations and computer vision research.

Composition of the Dataset

DODD is a compilation of images from multiple publicly accessible datasets, selected and assembled to create challenging occlusion-heavy scenes. The dataset includes a total of 121 images, featuring:

Individuals partially occluded by environmental elements such as debris, vegetation, and floodwater.

20 negative samples (images without any human presence), to serve as control cases for evaluation.

The datasets used to create DODD include:

Saied Fire Dataset: Focused on occlusions caused by smoke and fire in disaster environments. Available at: [Kaggle - Saied Fire Dataset](https://www.kaggle.com/datasets/phylake1337/fire-dataset?select=fire_datase)

Telperion DisasterDatasetRaw: Used for additional scenes involving natural disaster conditions like earthquakes and floods. Available at: [Kaggle - Telperion DisasterDatasetRaw](https://kaggle.com/datasets/telperion/diasterdatasetraw/data)

Each dataset was selected to ensure that DODD features realistic and complex scenarios to rigorously test human detection models in occluded environments.
